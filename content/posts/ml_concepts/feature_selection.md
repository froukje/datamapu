+++
title = 'Feature Selection: Regression vs. Classification'
date = 2023-12-11T22:56:54+01:00
draft = true
featured_image = ''
tags = ["Data Science", "Machine Learning", "Classification", "Regression"]
categories = ["Data Science", "Machine Learning", "Classification", "Regression"]
keywords = ["Data Science", "Machine Learning", "Deep Learning", "Classification", "Regression"]
+++

## Introduction

*Feature Selection* is the process to determine te most suitable subset of the total number of available features for modelling. This is usefull to

1. **Improve Model Performance.** Redundant and irrelevant features may be misleading for the model.

2. **Reduce overfitting.** Features that are not useful for the model can be considered as noise. When these are removed, we have less noise in the data.

3. **Decrease Training Time.** The more data, the longer takes the training.

## Feature Selection Methods

In this post we will only discuss feature selection methods for [supervised machine learning]({{< ref "supervised_unsupervised">}}) algorithms.

### Wrapper Methods

### Filter Methods

## Example
**Feature Selection: Regression**

correlation

**Feature Selection: Classification**

ANOVA

## Summary
