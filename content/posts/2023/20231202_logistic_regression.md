+++
title = 'Logistic Regression - Explained'
date = 2023-12-02T09:31:24+01:00
draft = true
featured_image = ''
tags = ["Data Science", "Machine Learning", "CLassification", "Logistic Regression"]
categories = ["Data Science", "Machine Learning", "Classification"]
keywords = ["Data Science", "Machine Learning", "Deep Learning", "Classification", "Logistic Regression"]
+++

## Introduction

In Logistic Regression is a [Supervised Machine Learning]({{< ref "20231017_supervised_unsupervised#supervised" >}} "Supervised Machine Learning") algorithm, where a model is developed, that relates the target variable to one or more input variables (features). However, in contrast to Linear [Linear Regression]({{< ref "20231113_linear_regression.md" >}} "Linear Regression") the target (dependent) variable is not numerical, but [categorical](https://en.wikipedia.org/wiki/Categorical_variable). That is the target can take values of two or more categories. An idealized example of two categories for the target variable is illustrated in the plot below. Note, that in real world examples the border between the two classes depending on the input feature (independ variable) will usually not be as clear as in this plot.

< image of (idealized) binary classsification example, (multi-class) >  

## Binary Logistic Regression

If the target variable contains two classes we speak of a Binary Logistic Regression. The target values for binary classification are usually denominated as '0' and '1'. In the previous plot 'potable' is the class '1' and 'not patable' is class '0'.

## Multiple Logistic Regression(?)

## Find Best Fit

## Log Reg vs Lin Reg

## Application

## Example
