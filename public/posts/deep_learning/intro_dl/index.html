<!DOCTYPE html>
<html lang="en-us">
  <head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    
    <title>Introduction to Deep Learning | </title>
    <meta name="viewport" content="width=device-width,minimum-scale=1">
    <meta name="description" content="In this article we will learn what Deep Learning is and understand the difference to AI and Machine Learning. Often these three terms are used interchangeable. They are however not the same. The following diagram illustrates how they are related.
Relation of Artificial Intelligence, Machine Learning and Deep Learning.
Artificial Intelligence. There are different definitions of Artificial Intelligence, but in general, they involve computers performing tasks that are usually associated with humans or other intelligent living systems.">
    <meta name="generator" content="Hugo 0.124.0">
    
    
    
    
      <meta name="robots" content="noindex, nofollow">
    

    
<link rel="stylesheet" href="/ananke/css/main.min.css" >



    
    
    
      
<link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />


    

    
    
    <meta property="og:title" content="Introduction to Deep Learning" />
<meta property="og:description" content="In this article we will learn what Deep Learning is and understand the difference to AI and Machine Learning. Often these three terms are used interchangeable. They are however not the same. The following diagram illustrates how they are related.
Relation of Artificial Intelligence, Machine Learning and Deep Learning.
Artificial Intelligence. There are different definitions of Artificial Intelligence, but in general, they involve computers performing tasks that are usually associated with humans or other intelligent living systems." />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://localhost:1313/posts/deep_learning/intro_dl/" /><meta property="og:image" content="http://localhost:1313/images/20131102_ai_ml_dl/ai_ml_dl.png" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-11-02T21:44:06+01:00" />
<meta property="article:modified_time" content="2023-11-02T21:44:06+01:00" />
<meta itemprop="name" content="Introduction to Deep Learning">
<meta itemprop="description" content="In this article we will learn what Deep Learning is and understand the difference to AI and Machine Learning. Often these three terms are used interchangeable. They are however not the same. The following diagram illustrates how they are related.
Relation of Artificial Intelligence, Machine Learning and Deep Learning.
Artificial Intelligence. There are different definitions of Artificial Intelligence, but in general, they involve computers performing tasks that are usually associated with humans or other intelligent living systems."><meta itemprop="datePublished" content="2023-11-02T21:44:06+01:00" />
<meta itemprop="dateModified" content="2023-11-02T21:44:06+01:00" />
<meta itemprop="wordCount" content="2250"><meta itemprop="image" content="http://localhost:1313/images/20131102_ai_ml_dl/ai_ml_dl.png" />
<meta itemprop="keywords" content="Data Science,Machine Learning,Deep Learning,Artificial Intelligence,Neural Nets," /><meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:image" content="http://localhost:1313/images/20131102_ai_ml_dl/ai_ml_dl.png" /><meta name="twitter:title" content="Introduction to Deep Learning"/>
<meta name="twitter:description" content="In this article we will learn what Deep Learning is and understand the difference to AI and Machine Learning. Often these three terms are used interchangeable. They are however not the same. The following diagram illustrates how they are related.
Relation of Artificial Intelligence, Machine Learning and Deep Learning.
Artificial Intelligence. There are different definitions of Artificial Intelligence, but in general, they involve computers performing tasks that are usually associated with humans or other intelligent living systems."/>

	<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<script>
MathJax = {
  tex: {
    inlineMath: [['$', '$'], ['\\(', '\\)']]
  }
};
</script>
<script id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
</script>

  </head>

  <body class="ma0 sans-serif bg-near-white">

    
   
  

  <header>
    <div class="bg-navy">
      <nav class="pv3 ph3 ph4-ns" role="navigation">
  <div class="flex-l justify-between items-center center">
    <a href="/" class="f3 fw2 hover-white no-underline white-90 dib">
      
        <img src="/logo_weiss_qualle.png" class="w100 mw5-ns" alt="" />
      
    </a>
    <div class="flex-l items-center">
      

      
        <ul class="pl0 mr3">
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="/" title="Home page">
              Home
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="/posts/" title="Articles page">
              Articles
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="/" title=" page">
              
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="/content/" title="Content page">
              Content
            </a>
          </li>
          
        </ul>
      
      
<div class="ananke-socials">
  
    
    <a href="https://twitter.com/datamapu" target="_blank" rel="noopener" class="twitter ananke-social-link link-transition stackoverflow link dib z-999 pt3 pt0-l mr1" title="Twitter link" aria-label="follow on Twitter——Opens in a new window">
      
        <span class="icon"><svg style="enable-background:new 0 0 67 67;" version="1.1" viewBox="0 0 67 67"  xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M37.167,22.283c-2.619,0.953-4.274,3.411-4.086,6.101  l0.063,1.038l-1.048-0.127c-3.813-0.487-7.145-2.139-9.974-4.915l-1.383-1.377l-0.356,1.017c-0.754,2.267-0.272,4.661,1.299,6.271  c0.838,0.89,0.649,1.017-0.796,0.487c-0.503-0.169-0.943-0.296-0.985-0.233c-0.146,0.149,0.356,2.076,0.754,2.839  c0.545,1.06,1.655,2.097,2.871,2.712l1.027,0.487l-1.215,0.021c-1.173,0-1.215,0.021-1.089,0.467  c0.419,1.377,2.074,2.839,3.918,3.475l1.299,0.444l-1.131,0.678c-1.676,0.976-3.646,1.526-5.616,1.568  C19.775,43.256,19,43.341,19,43.405c0,0.211,2.557,1.397,4.044,1.864c4.463,1.377,9.765,0.783,13.746-1.568  c2.829-1.673,5.657-5,6.978-8.221c0.713-1.716,1.425-4.851,1.425-6.354c0-0.975,0.063-1.102,1.236-2.267  c0.692-0.678,1.341-1.419,1.467-1.631c0.21-0.403,0.188-0.403-0.88-0.043c-1.781,0.636-2.033,0.551-1.152-0.402  c0.649-0.678,1.425-1.907,1.425-2.267c0-0.063-0.314,0.042-0.671,0.233c-0.377,0.212-1.215,0.53-1.844,0.72l-1.131,0.361l-1.027-0.7  c-0.566-0.381-1.361-0.805-1.781-0.932C39.766,21.902,38.131,21.944,37.167,22.283z M33,64C16.432,64,3,50.569,3,34S16.432,4,33,4  s30,13.431,30,30S49.568,64,33,64z" style="fill-rule:evenodd;clip-rule:evenodd;"/></svg>
</span>
      
<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000"  xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;"/>
</svg>
</span></a>
  
    
    <a href="https://www.linkedin.com/in/datamapu-ml-91a2622a3/" target="_blank" rel="noopener" class="linkedin ananke-social-link link-transition stackoverflow link dib z-999 pt3 pt0-l mr1" title="LinkedIn link" aria-label="follow on LinkedIn——Opens in a new window">
      
        <span class="icon"><svg style="enable-background:new 0 0 65 65;" version="1.1" viewBox="0 0 65 65"  xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
  <path d="M50.837,48.137V36.425c0-6.275-3.35-9.195-7.816-9.195  c-3.604,0-5.219,1.983-6.119,3.374V27.71h-6.79c0.09,1.917,0,20.427,0,20.427h6.79V36.729c0-0.609,0.044-1.219,0.224-1.655  c0.49-1.22,1.607-2.483,3.482-2.483c2.458,0,3.44,1.873,3.44,4.618v10.929H50.837z M22.959,24.922c2.367,0,3.842-1.57,3.842-3.531  c-0.044-2.003-1.475-3.528-3.797-3.528s-3.841,1.524-3.841,3.528c0,1.961,1.474,3.531,3.753,3.531H22.959z M34,64  C17.432,64,4,50.568,4,34C4,17.431,17.432,4,34,4s30,13.431,30,30C64,50.568,50.568,64,34,64z M26.354,48.137V27.71h-6.789v20.427  H26.354z" style="fill-rule:evenodd;clip-rule:evenodd;"/>
</svg>
</span>
      
<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000"  xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;"/>
</svg>
</span></a>
  
</div>

    </div>
  </div>
</nav>

    </div>
  </header>



    <main class="pb7" role="main">
      
  
  <article class="flex-l flex-wrap justify-between mw8 center ph3">
    <header class="mt4 w-100">
      <aside class="instapaper_ignoref b helvetica tracked">
          
        POSTS
      </aside>
      










  <div id="sharing" class="mt3 ananke-socials">
    
      
      <a href="https://twitter.com/share?url=http://localhost:1313/posts/deep_learning/intro_dl/&amp;text=Introduction%20to%20Deep%20Learning" class="ananke-social-link twitter no-underline" aria-label="share on Twitter">
        
        <span class="icon"> <svg style="enable-background:new 0 0 67 67;" version="1.1" viewBox="0 0 67 67"  xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M37.167,22.283c-2.619,0.953-4.274,3.411-4.086,6.101  l0.063,1.038l-1.048-0.127c-3.813-0.487-7.145-2.139-9.974-4.915l-1.383-1.377l-0.356,1.017c-0.754,2.267-0.272,4.661,1.299,6.271  c0.838,0.89,0.649,1.017-0.796,0.487c-0.503-0.169-0.943-0.296-0.985-0.233c-0.146,0.149,0.356,2.076,0.754,2.839  c0.545,1.06,1.655,2.097,2.871,2.712l1.027,0.487l-1.215,0.021c-1.173,0-1.215,0.021-1.089,0.467  c0.419,1.377,2.074,2.839,3.918,3.475l1.299,0.444l-1.131,0.678c-1.676,0.976-3.646,1.526-5.616,1.568  C19.775,43.256,19,43.341,19,43.405c0,0.211,2.557,1.397,4.044,1.864c4.463,1.377,9.765,0.783,13.746-1.568  c2.829-1.673,5.657-5,6.978-8.221c0.713-1.716,1.425-4.851,1.425-6.354c0-0.975,0.063-1.102,1.236-2.267  c0.692-0.678,1.341-1.419,1.467-1.631c0.21-0.403,0.188-0.403-0.88-0.043c-1.781,0.636-2.033,0.551-1.152-0.402  c0.649-0.678,1.425-1.907,1.425-2.267c0-0.063-0.314,0.042-0.671,0.233c-0.377,0.212-1.215,0.53-1.844,0.72l-1.131,0.361l-1.027-0.7  c-0.566-0.381-1.361-0.805-1.781-0.932C39.766,21.902,38.131,21.944,37.167,22.283z M33,64C16.432,64,3,50.569,3,34S16.432,4,33,4  s30,13.431,30,30S49.568,64,33,64z" style="fill-rule:evenodd;clip-rule:evenodd;"/></svg>
</span>
        
      </a>
    
      
      <a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=http://localhost:1313/posts/deep_learning/intro_dl/&amp;title=Introduction%20to%20Deep%20Learning" class="ananke-social-link linkedin no-underline" aria-label="share on LinkedIn">
        
        <span class="icon"> <svg style="enable-background:new 0 0 65 65;" version="1.1" viewBox="0 0 65 65"  xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
  <path d="M50.837,48.137V36.425c0-6.275-3.35-9.195-7.816-9.195  c-3.604,0-5.219,1.983-6.119,3.374V27.71h-6.79c0.09,1.917,0,20.427,0,20.427h6.79V36.729c0-0.609,0.044-1.219,0.224-1.655  c0.49-1.22,1.607-2.483,3.482-2.483c2.458,0,3.44,1.873,3.44,4.618v10.929H50.837z M22.959,24.922c2.367,0,3.842-1.57,3.842-3.531  c-0.044-2.003-1.475-3.528-3.797-3.528s-3.841,1.524-3.841,3.528c0,1.961,1.474,3.531,3.753,3.531H22.959z M34,64  C17.432,64,4,50.568,4,34C4,17.431,17.432,4,34,4s30,13.431,30,30C64,50.568,50.568,64,34,64z M26.354,48.137V27.71h-6.789v20.427  H26.354z" style="fill-rule:evenodd;clip-rule:evenodd;"/>
</svg>
</span>
        
      </a>
    
  </div>


      <h1 class="f1 athelas mt3 mb1">Introduction to Deep Learning</h1>
      
      
      
      <time class="f6 mv4 dib tracked" datetime="2023-11-02T21:44:06+01:00">November 2, 2023</time>
      

      
      
        <span class="f6 mv4 dib tracked"> - 11 minutes read </span>
        <span class="f6 mv4 dib tracked"> - 2250 words </span>
      
    </header>
    <div class="nested-copy-line-height lh-copy serif f4 nested-links mid-gray pr4-l w-two-thirds-l"><p>In this article we will learn what Deep Learning is and understand the difference to AI and Machine Learning. Often these three terms are used interchangeable. They are however not the same. The following diagram illustrates how they are related.</p>
<p><img src="/images/20231102_ai_ml_dl/ai_ml_dl.png" alt="ai_ml_dl">
<em>Relation of Artificial Intelligence, Machine Learning and Deep Learning.</em></p>
<p><strong>Artificial Intelligence.</strong> There are different definitions of Artificial Intelligence, but in general, they involve computers performing tasks that are usually associated with humans or other intelligent living systems. This is the definition given on Wikimedia:
It says: “[AI is] Mimicking the intelligence or behavioral pattern of humans or any living entity”</p>
<p><strong>Machine Learning.</strong> Machine learning is a subset of Artificial Intelligence. It describes the process where a computer can “learn” from data, without a given set of rules. In practice, these terms are often not well distinguished. People often talk about ML, but refer to it as AI.</p>
<p><strong>Deep Learning.</strong> Deep Learning is a particular type of Machine Learning, which uses Neural Nets as models. Neural Nets were inspired by the way neurons in our brain work.</p>
<h3 id="classical-programming-vs-machine-learning">Classical Programming vs. Machine Learning</h3>
<p>In this article we are going to learn about Deep Learning, which, as we just saw, is a subset of Machine Learning. Machine Learning differs conceptionally from classical programming. In classical programming we use data and rules to get the answers to a problem.
In contrast, in Machine Learning we use the data and the answers to a problem to achieve the rules. This is illustrated in the following chart.</p>
<p><img src="/images/20231102_ai_ml_dl/classical_ml.png" alt="ai_ml_dl">
<em>Classical programming vs. Machine Learning.</em></p>
<h3 id="what-is-a-neural-net">What is a Neural Net?</h3>
<p>A Neural Net is a special type of Machine Learning model which is used for Deep Learning.
It is often illustrated as shown in the next plot. The name and structure of a Neural Net are inspired by the human brain, mimicking the way that biological neurons signal to one another. However, other than inspiration and naming, they are actually not very similar. A neural network consists of connected computational units, which are called neurons.</p>
<p><img src="/images/20231102_ai_ml_dl/neural_net.png" alt="ai_ml_dl">
<em>Illustration of a Neural Net.</em></p>
<p><strong>Neuron</strong></p>
<p>Let&rsquo;s zoom in and understand how a <em>neuron</em> works. The following plot illustrates a single neuron in more detail.
Each neuron has one or more floating point inputs, the so-called input data, here shown as $x_1$ to $x_n$.
Each of these input numbers is multiplied by a weight - $w_1$ to $w_n$.
Then the weighted sum of the inputs is taken and additionally, an extra constant weight, which is the bias term, is added, here shown as $b$. These weights ($w_1$ to $w_n$) are learned during the training of the Neural Net. We will discuss how this exactly works later.
Next, a non-linear function - the so-called <em>activation function</em>, is applied to this sum.
This is a pre-defined function and we will see in the next paragraph what such an activation function looks like.
Finally, the neuron returns an output value, which is also a floating point number.</p>
<p><img src="/images/20231102_ai_ml_dl/neuron.png" alt="ai_ml_dl">
<em>Illustration of one Neuron of a Neural Net.</em></p>
<p><strong>Activation Function</strong></p>
<p>The purpose of the activation function is to introduce non-linearity into the output of a neuron.
A Neural Network without an activation function is essentially just a linear regression model. The activation function does the non-linear transformation to the input, making it capable to learn and perform more complex tasks.
Some typical activation functions are:</p>
<p>The <strong>Binary Stepfunction</strong> is $0$ for $x &lt;= 0$ and $1$ elsewhere. This is one of the simplest activation functions.
A threshold value is used to decide whether a neuron is activated or not. If the input is greater than a certain threshold, the neuron is activated, else it is not activated. If it is not activated, the output is not passed on to the next hidden layer. The binary stepfunction can only be used for binary classification and not for multiple classification problems. Further, the gradient of this activation function is $0$, which means it should not be used in a hidden layer, but only in the output layer.</p>
<p>The <strong>Rectified Linear Unit</strong>, or short <strong>ReLU</strong>, is $0$ for $x &lt;= 0$ and $x$ elsewhere this is one of the most commonly used activation functions. With the ReLU function, only neurons are activated when the input of the activation function is positive. That is, not all neurons are activated at the same time. This fact makes the ReLU computationally efficient. However, it may also result in so-called &ldquo;dead neurons&rdquo; - i.e. neurons that are never activated.</p>
<p>The <strong>Leaky ReLU</strong> is similar to the ReLU but it has a small slope for negative values. This activation function is preferred when we may have sparse gradients. The Leaky ReLU overcomes the problems of the ReLU activation function, that some neurons are never activated.</p>
<p>The output of the <strong>Sigmoid activation function</strong> is between $0$ and $1$. It is preferred when the output is a probability. The Sigmoid-activation function is differentiable with a smooth gradient. A disadvantage is that the gradient tends to vanish, because the derivative of the sigmoid function is flat. Also, the sigmoid function is not symmetric around $0$, which makes the training of a Neural Net more complicated. It is preferred to be used for the output layer and not for hidden layers.</p>
<p>Similar, but going from $-1$ to $1$ is the <strong>Hyperbolic Tangent (Tanh)</strong>. Compared to the sigmoid function, the Tanh is centered around $0$. It is usually used in hidden layers, as it helps to center the data. It has the same issue considering vanishing gradients as the sigmoid activation function.</p>
<p>Also similar is the <strong>Inverse Tangent function (ArcTan)</strong>, which goes from $-π/2$ to $π/2$. It has the same advantages and disadvantages as the Tanh activation function.</p>
<p><img src="/images/20231102_ai_ml_dl/activation.png" alt="ai_ml_dl">
<em>Most common activation functions.</em></p>
<p><strong>Neural Net</strong></p>
<p>Multiple neurons can be joined together by connecting the output of one neuron with the input of another. This then results in a Neural Net as illustrated in the next plot. The connections are associated with weights that determine the “strength” of the connection. The weights - as mentioned earlier - are adjusted during training. Several neurons are aggregated into layers in a Neural Net. We distinguish between the <em>input layer</em> at the beginning, the <em>output layer</em> at the end, and the so-called <em>hidden layers</em> in between. In the following plot, the weights are drawn associated to layers. They are, however, different for each connection. That is $w_1$ to $w_4$ in this illustration are vectors, that contain the weights for each connection. The signal - that is the data - travels from the input to the output and passes through the hidden layers.</p>
<p><img src="/images/20231102_ai_ml_dl/layer.png" alt="ai_ml_dl">
<em>Illustration of a Neural Net with 5 layers: 1 input layer, 3 hidden layers, and 1 output layer.</em></p>
<h3 id="how-does-a-neural-net-learn">How does a Neural Net Learn?</h3>
<p>Until now, we have seen how a neural net is organized. But we didn’t discuss yet, how the weights we use to calculate the output are determined. The process of finding the weights and bias is called <em>training</em>. This is the phase where the Neural Net is learning. Training a neural net is an iterative process. On a high level, the training process looks like this:</p>
<p><img src="/images/20231102_ai_ml_dl/neural_net_learning.png" alt="ai_ml_dl">
<em>Illustration of the learning process of a Neural Net.</em></p>
<ol>
<li>Initially the weights are randomly generated.</li>
<li>Then the output of the Neural Net is calculated. This is the so-called forward pass.</li>
<li>Next the error between the output of the Neural Net and the true labels is calculated. This is the so-called loss. In the beginning - with random weights - the results of the Neural Net will usually not be good.</li>
<li>We check if the stopping criterium, which we defined is fullfilled.</li>
<li>If it is not fulfilled, the weights are adjusted in the so-called backward pass and the process starts again, i.e. we calculate the output (with the new weights), calculate the error compared to the true labels, which is then hopefully smaller than before - if the stopping criterion is not fulfilled, we adjust the weights, and so on. This is repeated until the stopping criterion is achieved, then the training ends.</li>
</ol>
<p><strong>In summary, this means the weights are iteratively adjusted and optimized, such that the error compared to the true values is minimized.</strong> But how can we achieve that the error gets smaller? To understand that, we have to focus on the loss. We have already mentioned the loss as the error between the Neural Net output and the true label. The function we use to calculate this error is the so-called loss function. The choice of the loss function depends on the problem you are considering. Typical loss functions are, the Mean Squared Error (MSE) for regression problems or cross-entropy for classification problems. The loss function is a function of the weights and biases. We want the loss to be as small as possible. In other words, this means that we want to minimize the loss function, with respect to the weights and the bias. That is, <strong>the goal for the training of a Neural Net is to adjust the weights, such that the loss function is minimized.</strong> There are different optimization techniques to approach this minimization problem. We will discuss the Gradient Descent, which is a standard algorithm for optimization.</p>
<h3 id="gradient_descent">Gradient Descent</h3>
<p>As we just learned, we have to minimize the loss function in order to train a Neural Net. To do this, we can use different optimization techniques. We will take a look at one of these algorithms - the <em>Gradient Descent</em>. We will give a high-level overview. Here we illustrate the algorithm with a simplified example. The plot below shows the MSE as loss function $L$. We consider the one-dimensional case, which means we assume $L$ is a function of just one weight ($w$).</p>
<p><img src="/images/20231102_ai_ml_dl/gradient_descent.gif" alt="ai_ml_dl">
<em>Ilustration of Gradient Descent.</em></p>
<p>In Gradient Descent we start with some random value for the weight - here illustrated as $w_1$ - then we take small steps towards the minimum. To understand Gradient Descent we have to recall what the gradient is. The gradient of a function at a specific point is the direction of the steepest ascent. That is, if we want to find the minimum, we have to move in the opposite direction, that is in the direction of the negative of the gradient. This is, the direction of the steepest descent. How big this step is, is defined by the step size, a variable also called <em>learning rate</em> in the context of Machine Learning. This is a hyperparameter we have to define. Hyperparameters in Deep Learning have the same meaning as in classical Machine Learning. They are  parameters whose values are used to control the learning process. In contrast to other parameters (such as e.g. weights), which are derived during training. When training a Neural Network we usually try different values. The calculation of the gradients is done by an algorithm called backpropagation. In this article we are not going into further detail. The choice of the learning rate influences the training. When the learning rate is very small, the training takes very long. If it is too large, we may miss the minimum. The weight of the next iteration is then updated by subtracting the learning rate multiplied by the gradient of the loss function at the previous weight.
$$w_{i+1} = w_{i} - \alpha \cdot \nabla_{w_i} L(w_i) $$
In practice, a lot of variants of Gradient Descent exist. For example, classical Gradient Descent is applied to the entire dataset, before the weights are updated. This may take long if the dataset is large. A common variant is the mini-batch gradient descent, where data is passed in mini-batches through the network and the updates are calculated after each mini-batch.</p>
<h3 id="how-much-data-do-we-need">How much Data do we need?</h3>
<p>A question often asked is, how much data is actually necessary to use Deep Learning. Deep Learning is known to need a large amount of data, but what does that mean? Unfortunately, there is no answer to this, in the sense of giving a specific number of data points.
The amount of data needed depends on different factors, such as e.g. the complexity of the task (what is not always known in advance), the quality of the available data, and the complexity of the network. In general, adding more data improves the performance, especially for complex tasks with large Neural Networks. However, if the data added is too similar to the data we already have, it will not give much new information to the Neural Network. If we don’t have much data available, but still want to use a complex Neural Net, we can can consider using a pretrained model (trained on a similar task) or data augmentation (especially when working with image data).</p>
<h3 id="summary">Summary</h3>
<p>We discussed how Deep Learning is defined and learned that Deep Learning is a subset of Machine Learning.
We introduced the structure of Neural Nets and learned that it consists of a set of connected neurons and that activation functions are used to introduce non-linearity into a Neural Net. We looked from a high-level perspective at how the learning process works and discussed that training a Neural Net is an iterative process, that aims to minimize the loss function. Lastly, we briefly discussed how much data is needed to apply Deep Learning. Unfortunately, there is no real answer to this question.
How much data is needed depends on the problem we want to solve, the network, and the quality of the data.
Generally speaking, we can say: the more data, the better.</p>
<hr>
<p>If this blog is useful for you, I&rsquo;m thankful for your support!



<a class="hugo-shortcodes-bmc-button" href="https://www.buymeacoffee.com/pumaline">
    <img src="https://img.buymeacoffee.com/button-api/?button_colour=ffdd00&amp;coffee_colour=ffffff&amp;emoji=&amp;font_colour=000000&amp;font_family=Cookie&amp;outline_colour=000000&amp;slug=pumaline&amp;text=Buy&#43;me&#43;a&#43;coffee" alt="Buy me a coffee" />
</a>
</p>
<ul class="pa0">
  
   <li class="list di">
     <a href="/tags/data-science/" class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">Data Science</a>
   </li>
  
   <li class="list di">
     <a href="/tags/machine-learning/" class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">Machine Learning</a>
   </li>
  
   <li class="list di">
     <a href="/tags/deep-learning/" class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">Deep Learning</a>
   </li>
  
   <li class="list di">
     <a href="/tags/artificial-intelligence/" class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">Artificial Intelligence</a>
   </li>
  
   <li class="list di">
     <a href="/tags/neural-nets/" class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">Neural Nets</a>
   </li>
  
</ul>
<div class="mt6 instapaper_ignoref">
      
      
      </div>
    </div>

    <aside class="w-30-l mt6-l">




  <div class="bg-light-gray pa3 nested-list-reset nested-copy-line-height nested-links">
    <p class="f5 b mb3">Related</p>
    <ul class="pa0 list">
	   
	     <li  class="mb2">
          <a href="/posts/ml_concepts/supervised_unsupervised/">Supervised versus Unsupervised Learning - Explained</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/posts/ml_concepts/classification_metrics/">Metrics for Classification Problems</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/posts/ml_concepts/regression_metrics/">Metrics for Regression Problems</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/posts/ml_concepts/datascience_lifecycle/">The Data Science Lifecycle</a>
        </li>
	    
    </ul>
</div>

</aside>

  </article>

    </main>
    <footer class="bg-navy bottom-0 w-100 pa3" role="contentinfo">
  <div class="flex justify-between">
  <a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href="http://localhost:1313/" >
    &copy; 
  </a>
    <div>
<div class="ananke-socials">
  
    
    <a href="https://twitter.com/datamapu" target="_blank" rel="noopener" class="twitter ananke-social-link link-transition stackoverflow link dib z-999 pt3 pt0-l mr1" title="Twitter link" aria-label="follow on Twitter——Opens in a new window">
      
        <span class="icon"><svg style="enable-background:new 0 0 67 67;" version="1.1" viewBox="0 0 67 67"  xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M37.167,22.283c-2.619,0.953-4.274,3.411-4.086,6.101  l0.063,1.038l-1.048-0.127c-3.813-0.487-7.145-2.139-9.974-4.915l-1.383-1.377l-0.356,1.017c-0.754,2.267-0.272,4.661,1.299,6.271  c0.838,0.89,0.649,1.017-0.796,0.487c-0.503-0.169-0.943-0.296-0.985-0.233c-0.146,0.149,0.356,2.076,0.754,2.839  c0.545,1.06,1.655,2.097,2.871,2.712l1.027,0.487l-1.215,0.021c-1.173,0-1.215,0.021-1.089,0.467  c0.419,1.377,2.074,2.839,3.918,3.475l1.299,0.444l-1.131,0.678c-1.676,0.976-3.646,1.526-5.616,1.568  C19.775,43.256,19,43.341,19,43.405c0,0.211,2.557,1.397,4.044,1.864c4.463,1.377,9.765,0.783,13.746-1.568  c2.829-1.673,5.657-5,6.978-8.221c0.713-1.716,1.425-4.851,1.425-6.354c0-0.975,0.063-1.102,1.236-2.267  c0.692-0.678,1.341-1.419,1.467-1.631c0.21-0.403,0.188-0.403-0.88-0.043c-1.781,0.636-2.033,0.551-1.152-0.402  c0.649-0.678,1.425-1.907,1.425-2.267c0-0.063-0.314,0.042-0.671,0.233c-0.377,0.212-1.215,0.53-1.844,0.72l-1.131,0.361l-1.027-0.7  c-0.566-0.381-1.361-0.805-1.781-0.932C39.766,21.902,38.131,21.944,37.167,22.283z M33,64C16.432,64,3,50.569,3,34S16.432,4,33,4  s30,13.431,30,30S49.568,64,33,64z" style="fill-rule:evenodd;clip-rule:evenodd;"/></svg>
</span>
      
<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000"  xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;"/>
</svg>
</span></a>
  
    
    <a href="https://www.linkedin.com/in/datamapu-ml-91a2622a3/" target="_blank" rel="noopener" class="linkedin ananke-social-link link-transition stackoverflow link dib z-999 pt3 pt0-l mr1" title="LinkedIn link" aria-label="follow on LinkedIn——Opens in a new window">
      
        <span class="icon"><svg style="enable-background:new 0 0 65 65;" version="1.1" viewBox="0 0 65 65"  xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
  <path d="M50.837,48.137V36.425c0-6.275-3.35-9.195-7.816-9.195  c-3.604,0-5.219,1.983-6.119,3.374V27.71h-6.79c0.09,1.917,0,20.427,0,20.427h6.79V36.729c0-0.609,0.044-1.219,0.224-1.655  c0.49-1.22,1.607-2.483,3.482-2.483c2.458,0,3.44,1.873,3.44,4.618v10.929H50.837z M22.959,24.922c2.367,0,3.842-1.57,3.842-3.531  c-0.044-2.003-1.475-3.528-3.797-3.528s-3.841,1.524-3.841,3.528c0,1.961,1.474,3.531,3.753,3.531H22.959z M34,64  C17.432,64,4,50.568,4,34C4,17.431,17.432,4,34,4s30,13.431,30,30C64,50.568,50.568,64,34,64z M26.354,48.137V27.71h-6.789v20.427  H26.354z" style="fill-rule:evenodd;clip-rule:evenodd;"/>
</svg>
</span>
      
<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000"  xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;"/>
</svg>
</span></a>
  
</div>
</div>
  </div>
</footer>

  </body>
</html>
