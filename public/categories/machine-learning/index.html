<!DOCTYPE html>
<html lang="en-us">
  <head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    
    <title></title>
    <meta name="viewport" content="width=device-width,minimum-scale=1">
    <meta name="description" content="Data Science and Machine Learning Blog">
    <meta name="generator" content="Hugo 0.126.1">
    
    
    
    
      <meta name="robots" content="noindex, nofollow">
    

    
<link rel="stylesheet" href="/ananke/css/main.min.css" >



    
    
    
      
<link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />


    

    
    
      <link href="/categories/machine-learning/index.xml" rel="alternate" type="application/rss+xml" title="" />
      <link href="/categories/machine-learning/index.xml" rel="feed" type="application/rss+xml" title="" />
      
    
    
    <meta property="og:url" content="http://localhost:1313/categories/machine-learning/">
  <meta property="og:title" content="Machine Learning">
  <meta property="og:description" content="Data Science and Machine Learning Blog">
  <meta property="og:locale" content="en_us">
  <meta property="og:type" content="website">
    <meta property="og:image" content="http://localhost:1313/static/images/datamapu_logo_schmal.png">

  <meta itemprop="name" content="Machine Learning">
  <meta itemprop="description" content="Data Science and Machine Learning Blog">
  <meta itemprop="dateModified" content="2024-05-08T20:55:43-03:00">
  <meta itemprop="image" content="http://localhost:1313/static/images/datamapu_logo_schmal.png">
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:image" content="http://localhost:1313/static/images/datamapu_logo_schmal.png">
  <meta name="twitter:title" content="Machine Learning">
  <meta name="twitter:description" content="Data Science and Machine Learning Blog">

	<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<script>
MathJax = {
  tex: {
    inlineMath: [['$', '$'], ['\\(', '\\)']]
  }
};
</script>
<script id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
</script>

  </head>

  <body class="ma0 sans-serif bg-near-white">

    

  <header>
    <div class="pb3-m pb6-l bg-navy">
      <nav class="pv3 ph3 ph4-ns" role="navigation">
  <div class="flex-l justify-between items-center center">
    <a href="/" class="f3 fw2 hover-white no-underline white-90 dib">
      
        <img src="/logo_weiss_qualle.png" class="w100 mw5-ns" alt="" />
      
    </a>
    <div class="flex-l items-center">
      

      
        <ul class="pl0 mr3">
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="/" title="Home page">
              Home
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="/posts/" title="Articles page">
              Articles
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="/" title=" page">
              
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="/content/" title="Content page">
              Content
            </a>
          </li>
          
        </ul>
      
      
<div class="ananke-socials">
  
    
    <a href="https://twitter.com/datamapu" target="_blank" rel="noopener" class="twitter ananke-social-link link-transition stackoverflow link dib z-999 pt3 pt0-l mr1" title="Twitter link" aria-label="follow on Twitter——Opens in a new window">
      
        <span class="icon"><svg style="enable-background:new 0 0 67 67;" version="1.1" viewBox="0 0 67 67"  xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M37.167,22.283c-2.619,0.953-4.274,3.411-4.086,6.101  l0.063,1.038l-1.048-0.127c-3.813-0.487-7.145-2.139-9.974-4.915l-1.383-1.377l-0.356,1.017c-0.754,2.267-0.272,4.661,1.299,6.271  c0.838,0.89,0.649,1.017-0.796,0.487c-0.503-0.169-0.943-0.296-0.985-0.233c-0.146,0.149,0.356,2.076,0.754,2.839  c0.545,1.06,1.655,2.097,2.871,2.712l1.027,0.487l-1.215,0.021c-1.173,0-1.215,0.021-1.089,0.467  c0.419,1.377,2.074,2.839,3.918,3.475l1.299,0.444l-1.131,0.678c-1.676,0.976-3.646,1.526-5.616,1.568  C19.775,43.256,19,43.341,19,43.405c0,0.211,2.557,1.397,4.044,1.864c4.463,1.377,9.765,0.783,13.746-1.568  c2.829-1.673,5.657-5,6.978-8.221c0.713-1.716,1.425-4.851,1.425-6.354c0-0.975,0.063-1.102,1.236-2.267  c0.692-0.678,1.341-1.419,1.467-1.631c0.21-0.403,0.188-0.403-0.88-0.043c-1.781,0.636-2.033,0.551-1.152-0.402  c0.649-0.678,1.425-1.907,1.425-2.267c0-0.063-0.314,0.042-0.671,0.233c-0.377,0.212-1.215,0.53-1.844,0.72l-1.131,0.361l-1.027-0.7  c-0.566-0.381-1.361-0.805-1.781-0.932C39.766,21.902,38.131,21.944,37.167,22.283z M33,64C16.432,64,3,50.569,3,34S16.432,4,33,4  s30,13.431,30,30S49.568,64,33,64z" style="fill-rule:evenodd;clip-rule:evenodd;"/></svg>
</span>
      
<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000"  xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;"/>
</svg>
</span></a>
  
    
    <a href="https://www.linkedin.com/in/datamapu-ml-91a2622a3/" target="_blank" rel="noopener" class="linkedin ananke-social-link link-transition stackoverflow link dib z-999 pt3 pt0-l mr1" title="LinkedIn link" aria-label="follow on LinkedIn——Opens in a new window">
      
        <span class="icon"><svg style="enable-background:new 0 0 65 65;" version="1.1" viewBox="0 0 65 65"  xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
  <path d="M50.837,48.137V36.425c0-6.275-3.35-9.195-7.816-9.195  c-3.604,0-5.219,1.983-6.119,3.374V27.71h-6.79c0.09,1.917,0,20.427,0,20.427h6.79V36.729c0-0.609,0.044-1.219,0.224-1.655  c0.49-1.22,1.607-2.483,3.482-2.483c2.458,0,3.44,1.873,3.44,4.618v10.929H50.837z M22.959,24.922c2.367,0,3.842-1.57,3.842-3.531  c-0.044-2.003-1.475-3.528-3.797-3.528s-3.841,1.524-3.841,3.528c0,1.961,1.474,3.531,3.753,3.531H22.959z M34,64  C17.432,64,4,50.568,4,34C4,17.431,17.432,4,34,4s30,13.431,30,30C64,50.568,50.568,64,34,64z M26.354,48.137V27.71h-6.789v20.427  H26.354z" style="fill-rule:evenodd;clip-rule:evenodd;"/>
</svg>
</span>
      
<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000"  xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;"/>
</svg>
</span></a>
  
</div>

    </div>
  </div>
</nav>

      <div class="tc-l pv3 ph3 ph4-ns">
        <h1 class="f2 f-subheadline-l fw2 light-silver mb0 lh-title">
          Machine Learning
        </h1>
        
      </div>
    </div>
  </header>


    <main class="pb7" role="main">
      
  <article class="cf pa3 pa4-m pa4-l">
    <div class="measure-wide-l center f4 lh-copy nested-copy-line-height nested-links mid-gray">
      <p>Below you will find pages that utilize the taxonomy term “Machine Learning”</p>
    </div>
  </article>
  <div class="mw8 center">
    <section class="flex-ns flex-wrap justify-around mt5">
      
        <div class="relative w-100  mb4 bg-white">
          <div class="relative w-100 mb4 bg-white nested-copy-line-height">
  <div class="bg-white mb3 pa4 gray overflow-hidden">
    <span class="f6 db">Posts</span>
    <h1 class="f3 near-black">
      <a href="/posts/classical_ml/gradient_boosting_variants/" class="link black dim">
        Gradient Boosting Variants - Sklearn vs. XGBoost vs. LightGBM vs. CatBoost
      </a>
    </h1>
    <div class="nested-links f5 lh-copy nested-copy-line-height">
      Introduction Gradient Boosting is an ensemble model which is built of a sequential series of shallow Decision Trees. The single trees are weak learners and have little predictive skill, that is only slightly higher than random guessing. Together, they form a strong learner with high predictive skill. For a more detailed explanatione, please refer to the post Gradient Boosting for Regression - Explained. In this article, we will discuss differet implementations of Gradient Boosting.
    </div>
  </div>
</div>

        </div>
      
        <div class="relative w-100  mb4 bg-white">
          <div class="relative w-100 mb4 bg-white nested-copy-line-height">
  <div class="bg-white mb3 pa4 gray overflow-hidden">
    <span class="f6 db">Posts</span>
    <h1 class="f3 near-black">
      <a href="/posts/classical_ml/gradient_boosting_classification_example/" class="link black dim">
        Gradient Boost for Classification Example
      </a>
    </h1>
    <div class="nested-links f5 lh-copy nested-copy-line-height">
      Introduction In this post, we develop a Gradient Boosting model for a binary classification. We focus on the calculations of each single step for a specific example chosen. For a more general explanation of the algorithm and the derivation of the formulas for the individual steps, please refer to Gradient Boost for Classification - Explained and Gradient Boost for Regression - Explained. Additionally, we show a simple example of how to apply Gradient Boosting for classification in Python.
    </div>
  </div>
</div>

        </div>
      
        <div class="relative w-100  mb4 bg-white">
          <div class="relative w-100 mb4 bg-white nested-copy-line-height">
  <div class="bg-white mb3 pa4 gray overflow-hidden">
    <span class="f6 db">Posts</span>
    <h1 class="f3 near-black">
      <a href="/posts/classical_ml/gradient_boosting_classification/" class="link black dim">
        Gradient Boost for Classification - Explained
      </a>
    </h1>
    <div class="nested-links f5 lh-copy nested-copy-line-height">
      Introduction Gradient Boosting is an ensemble machine learning model, that - as the name suggests - is based on boosting. An ensemble model based on boosting refers to a model that sequentially builds models, and the new model depends on the previous model. In Gradient Boosting these models are built such that they improve the error of the previous model. These individual models are so-called weak learners, which means they have low predictive skills.
    </div>
  </div>
</div>

        </div>
      
        <div class="relative w-100  mb4 bg-white">
          <div class="relative w-100 mb4 bg-white nested-copy-line-height">
  <div class="bg-white mb3 pa4 gray overflow-hidden">
    <span class="f6 db">Posts</span>
    <h1 class="f3 near-black">
      <a href="/posts/classical_ml/gradient_boosting_regression_example/" class="link black dim">
        Gradient Boost for Regression - Example
      </a>
    </h1>
    <div class="nested-links f5 lh-copy nested-copy-line-height">
      Introduction In this post, we will go through the development of a Gradient Boosting model for a regression problem, considering a simplified example. We calculate the individual steps in detail, which are defined and explained in the separate post Gradient Boost for Regression - Explained. Please refer to this post for a more general and detailed explanation of the algorithm.
Data We will use a simplified dataset consisting of only 10 samples, which describes how many meters a person has climbed, depending on their age, whether they like height, and whether they like goats.
    </div>
  </div>
</div>

        </div>
      
        <div class="relative w-100  mb4 bg-white">
          <div class="relative w-100 mb4 bg-white nested-copy-line-height">
  <div class="bg-white mb3 pa4 gray overflow-hidden">
    
    <h1 class="f3 near-black">
      <a href="/backpropagation/" class="link black dim">
        Backpropagation Step by Step
      </a>
    </h1>
    <div class="nested-links f5 lh-copy nested-copy-line-height">
      Introduction A neural network consists of a set of parameters - the weights and biases - which define the outcome of the network, that is the predictions. When training a neural network we aim to adjust these weights and biases such that the predictions improve. To achieve that Backpropagation is used. In this post, we discuss how backpropagation works, and explain it in detail for four simple examples. The first two examples will contain all the calculations, the last two will only illustrate the equations that need to be calculated.
    </div>
  </div>
</div>

        </div>
      
        <div class="relative w-100  mb4 bg-white">
          <div class="relative w-100 mb4 bg-white nested-copy-line-height">
  <div class="bg-white mb3 pa4 gray overflow-hidden">
    <span class="f6 db">Posts</span>
    <h1 class="f3 near-black">
      <a href="/posts/deep_learning/backpropagation/" class="link black dim">
        Backpropagation Step by Step
      </a>
    </h1>
    <div class="nested-links f5 lh-copy nested-copy-line-height">
      Introduction A neural network consists of a set of parameters - the weights and biases - which define the outcome of the network, that is the predictions. When training a neural network we aim to adjust these weights and biases such that the predictions improve. To achieve that Backpropagation is used. In this post, we discuss how backpropagation works, and explain it in detail for three simple examples. The first two examples will contain all the calculations, for the last one we will only illustrate the equations that need to be calculated.
    </div>
  </div>
</div>

        </div>
      
        <div class="relative w-100  mb4 bg-white">
          <div class="relative w-100 mb4 bg-white nested-copy-line-height">
  <div class="bg-white mb3 pa4 gray overflow-hidden">
    <span class="f6 db">Posts</span>
    <h1 class="f3 near-black">
      <a href="/posts/ml_concepts/gradient_descent/" class="link black dim">
        Gradient Descent
      </a>
    </h1>
    <div class="nested-links f5 lh-copy nested-copy-line-height">
      Introduction Gradient Descent is a mathematical optimization technique, which is used to find the local minima of a function. In Machine Learning it is used in a variety of models such as Gradient Boosting or Neural Networks to minimize the Loss Function. It is an iterative algorithm that takes small steps towards the minimum in every iteration. The idea is to start at a random point and then take a small step into the direction of the steepest descent of this point.
    </div>
  </div>
</div>

        </div>
      
        <div class="relative w-100  mb4 bg-white">
          <div class="relative w-100 mb4 bg-white nested-copy-line-height">
  <div class="bg-white mb3 pa4 gray overflow-hidden">
    <span class="f6 db">Posts</span>
    <h1 class="f3 near-black">
      <a href="/posts/ml_concepts/loss_functions/" class="link black dim">
        Loss Functions in Machine Learning
      </a>
    </h1>
    <div class="nested-links f5 lh-copy nested-copy-line-height">
      Introduction In Machine Learning loss functions are used to evaluate the model. They compare the true target values with the predicted ones and are directly related to the error of the predictions. During the training of a model, the loss function is aimed to be optimized to minimize the error of the predictions. It is a general convention to define a loss function such that it is minimized rather than maximized.
    </div>
  </div>
</div>

        </div>
      
        <div class="relative w-100  mb4 bg-white">
          <div class="relative w-100 mb4 bg-white nested-copy-line-height">
  <div class="bg-white mb3 pa4 gray overflow-hidden">
    <span class="f6 db">Posts</span>
    <h1 class="f3 near-black">
      <a href="/posts/classical_ml/gradient_boosting_regression/" class="link black dim">
        Gradient Boost for Regression - Explained
      </a>
    </h1>
    <div class="nested-links f5 lh-copy nested-copy-line-height">
      Introduction Gradient Boosting, also called Gradient Boosting Machine (GBM) is a type of supervised Machine Learning algorithm that is based on ensemble learning. It consists of a sequential series of models, each one trying to improve the errors of the previous one. It can be used for both regression and classification tasks. In this post, we introduce the algorithm and then explain it in detail for a regression task. We will look at the general formulation of the algorithm and then derive and simplify the individual steps for the most common use case, which uses Decision Trees as underlying models and a variation of the Mean Squared Error (MSE) as loss function.
    </div>
  </div>
</div>

        </div>
      
        <div class="relative w-100  mb4 bg-white">
          <div class="relative w-100 mb4 bg-white nested-copy-line-height">
  <div class="bg-white mb3 pa4 gray overflow-hidden">
    <span class="f6 db">Posts</span>
    <h1 class="f3 near-black">
      <a href="/posts/classical_ml/adaboost_example_reg/" class="link black dim">
        Adaboost for Regression - Example
      </a>
    </h1>
    <div class="nested-links f5 lh-copy nested-copy-line-height">
      Introduction AdaBoost is an ensemble model that sequentially builds new models based on the errors of the previous model to improve the predictions. The most common case is to use Decision Trees as base models. Very often the examples explained are for classification tasks. AdaBoost can, however, also be used for regression problems. This is what we will focus on in this post. This article covers the detailed calculations of a simplified example.
    </div>
  </div>
</div>

        </div>
      
        <div class="relative w-100  mb4 bg-white">
          <div class="relative w-100 mb4 bg-white nested-copy-line-height">
  <div class="bg-white mb3 pa4 gray overflow-hidden">
    <span class="f6 db">Posts</span>
    <h1 class="f3 near-black">
      <a href="/posts/classical_ml/adaboost_example_clf/" class="link black dim">
        AdaBoost for Classification - Example
      </a>
    </h1>
    <div class="nested-links f5 lh-copy nested-copy-line-height">
      Introduction AdaBoost is an ensemble model that is based on Boosting. The individual models are so-called weak learners, which means that they have only little predictive skill, and they are sequentially built to improve the errors of the previous one. A detailed description of the Algorithm can be found in the separate article AdaBoost - Explained. In this post, we will focus on a concrete example for a classification task and develop the final ensemble model in detail.
    </div>
  </div>
</div>

        </div>
      
        <div class="relative w-100  mb4 bg-white">
          <div class="relative w-100 mb4 bg-white nested-copy-line-height">
  <div class="bg-white mb3 pa4 gray overflow-hidden">
    <span class="f6 db">Posts</span>
    <h1 class="f3 near-black">
      <a href="/posts/classical_ml/adaboost/" class="link black dim">
        AdaBoost - Explained
      </a>
    </h1>
    <div class="nested-links f5 lh-copy nested-copy-line-height">
      Introduction AdaBoost is an example of an ensemble supervised Machine Learning model. It consists of a sequential series of models, each one focussing on the errors of the previous one, trying to improve them. The most common underlying model is the Decision Tree, other models are however possible. In this post, we will introduce the algorithm of AdaBoost and have a look at a simplified example for a classification task using sklearn.
    </div>
  </div>
</div>

        </div>
      
        <div class="relative w-100  mb4 bg-white">
          <div class="relative w-100 mb4 bg-white nested-copy-line-height">
  <div class="bg-white mb3 pa4 gray overflow-hidden">
    <span class="f6 db">Posts</span>
    <h1 class="f3 near-black">
      <a href="/posts/ml_concepts/bias_variance/" class="link black dim">
        Bias and Variance
      </a>
    </h1>
    <div class="nested-links f5 lh-copy nested-copy-line-height">
      Introduction In Machine Learning different error sources exist. Some errors cannot be avoided, for example, due to unknown variables in the system analyzed. These errors are called irreducible errors. On the other hand, reducible errors, are errors that can be reduced to improve the model&rsquo;s skill. Bias and Variance are two of the latter. They are concepts used in supervised Machine Learning to evaluate the model&rsquo;s output compared to the true values.
    </div>
  </div>
</div>

        </div>
      
        <div class="relative w-100  mb4 bg-white">
          <div class="relative w-100 mb4 bg-white nested-copy-line-height">
  <div class="bg-white mb3 pa4 gray overflow-hidden">
    <span class="f6 db">Posts</span>
    <h1 class="f3 near-black">
      <a href="/posts/ml_concepts/ensemble/" class="link black dim">
        Ensemble Models - Illustrated
      </a>
    </h1>
    <div class="nested-links f5 lh-copy nested-copy-line-height">
      Introduction In Ensemble Learning multiple Machine Learning models are combined into one single prediction to improve the predictive skill. The individual models can be of different types or the same. Ensemble learning is based on &ldquo;the wisdom of the crowds&rdquo;, which assumes that the expected value of multiple estimates is more accurate than a single estimate. Ensemble learning can be used for regression or classification tasks. Three main types of Ensemble Learning method are most common.
    </div>
  </div>
</div>

        </div>
      
        <div class="relative w-100  mb4 bg-white">
          <div class="relative w-100 mb4 bg-white nested-copy-line-height">
  <div class="bg-white mb3 pa4 gray overflow-hidden">
    <span class="f6 db">Posts</span>
    <h1 class="f3 near-black">
      <a href="/posts/classical_ml/random_forest/" class="link black dim">
        Random Forests - Explained
      </a>
    </h1>
    <div class="nested-links f5 lh-copy nested-copy-line-height">
      Introduction A Random Forest is a supervised Machine Learning model, that is built on Decision Trees. To understand how a Random Forest works, you should be familiar with Decision Trees. You can find an introduction in the separate article Decision Trees - Explained. A major disadvantage of Decision Trees is that they tend to overfit and often have difficulties to generalize to new data. Random Forests try to overcome this weakness.
    </div>
  </div>
</div>

        </div>
      
        <div class="relative w-100  mb4 bg-white">
          <div class="relative w-100 mb4 bg-white nested-copy-line-height">
  <div class="bg-white mb3 pa4 gray overflow-hidden">
    <span class="f6 db">Posts</span>
    <h1 class="f3 near-black">
      <a href="/posts/classical_ml/decision_tree_regression_example/" class="link black dim">
        Decision Trees for Regression - Example
      </a>
    </h1>
    <div class="nested-links f5 lh-copy nested-copy-line-height">
      Introduction A Decision Tree is a simple Machine Learning model that can be used for both regression and classification tasks. In the article Decision Trees for Classification - Example a Decision Tree for a classification problem is developed in detail. In this post, we consider a regression problem and build a Decision Tree step by step for a simplified dataset. Additionally, we use sklearn to fit a model to the data and compare the results.
    </div>
  </div>
</div>

        </div>
      
        <div class="relative w-100  mb4 bg-white">
          <div class="relative w-100 mb4 bg-white nested-copy-line-height">
  <div class="bg-white mb3 pa4 gray overflow-hidden">
    <span class="f6 db">Posts</span>
    <h1 class="f3 near-black">
      <a href="/posts/classical_ml/decision_tree_classification_example/" class="link black dim">
        Decision Trees for Classification - Example
      </a>
    </h1>
    <div class="nested-links f5 lh-copy nested-copy-line-height">
      Introduction Decision Trees are a powerful, yet simple Machine Learning Model. An advantage of their simplicity is that we can build and understand them step by step. In this post, we are looking at a simplified example to build an entire Decision Tree by hand for a classification task. After calculating the tree, we will use the sklearn package and compare the results. To learn how to build a Decision Tree for a regression problem, please refer to the article Decision Trees for Regression - Example.
    </div>
  </div>
</div>

        </div>
      
        <div class="relative w-100  mb4 bg-white">
          <div class="relative w-100 mb4 bg-white nested-copy-line-height">
  <div class="bg-white mb3 pa4 gray overflow-hidden">
    <span class="f6 db">Posts</span>
    <h1 class="f3 near-black">
      <a href="/posts/classical_ml/decision_trees/" class="link black dim">
        Decision Trees - Explained
      </a>
    </h1>
    <div class="nested-links f5 lh-copy nested-copy-line-height">
      Introduction A Decision Tree is a supervised Machine Learning algorithm that can be used for both regression and classification problems. It is a non-parametric model, which means there is no specific mathematical function underlying to fit the data (in contrast to e.g. Linear Regression or Logistic Regression), but the algorithm only learns from the data itself. Decision Trees learn rules for decision making and used to be drawn manually before Machine Learning came up.
    </div>
  </div>
</div>

        </div>
      
        <div class="relative w-100  mb4 bg-white">
          <div class="relative w-100 mb4 bg-white nested-copy-line-height">
  <div class="bg-white mb3 pa4 gray overflow-hidden">
    <span class="f6 db">Posts</span>
    <h1 class="f3 near-black">
      <a href="/posts/ml_concepts/feature_selection/" class="link black dim">
        Feature Selection Methods
      </a>
    </h1>
    <div class="nested-links f5 lh-copy nested-copy-line-height">
      Introduction Feature Selection is the process of determining the most suitable subset of the total number of available features for modeling. It helps to understand which features contribute most to the target data. This is usefull to
Improve Model Performance. Redundant and irrelevant features may be misleading for the model. Additionally, if the feature space is too large compared to the sample size. This is called the curse of dimensionality and may reduce the model&rsquo;s performance.
    </div>
  </div>
</div>

        </div>
      
        <div class="relative w-100  mb4 bg-white">
          <div class="relative w-100 mb4 bg-white nested-copy-line-height">
  <div class="bg-white mb3 pa4 gray overflow-hidden">
    <span class="f6 db">Posts</span>
    <h1 class="f3 near-black">
      <a href="/posts/classical_ml/logistic_regression/" class="link black dim">
        Logistic Regression - Explained
      </a>
    </h1>
    <div class="nested-links f5 lh-copy nested-copy-line-height">
      Introduction Logistic Regression is a Supervised Machine Learning algorithm, in which a model is developed, that relates the target variable to one or more input variables (features). However, in contrast to Linear Regression the target (dependent) variable is not numerical, but categorical. That is the target variable can be classified in different categories (e.g.: &rsquo;test passed&rsquo; or &rsquo;test not passed&rsquo;). An idealized example of two categories for the target variable is illustrated in the plot below.
    </div>
  </div>
</div>

        </div>
      
        <div class="relative w-100  mb4 bg-white">
          <div class="relative w-100 mb4 bg-white nested-copy-line-height">
  <div class="bg-white mb3 pa4 gray overflow-hidden">
    <span class="f6 db">Posts</span>
    <h1 class="f3 near-black">
      <a href="/posts/classical_ml/linear_regression_example/" class="link black dim">
        Linear Regression - Analytical Solution and Simplified Example
      </a>
    </h1>
    <div class="nested-links f5 lh-copy nested-copy-line-height">
      Introduction In a previous article, we introduced Linear Regression in detail and more generally, showed how to find the best model and discussed its chances and limitations. In this post, we are looking at a concrete example. We are going to calculate the slope and the intercept from a Simple Linear Regression analytically, looking at the example data provided in the next plot.
Illustration of a simple linear regression between the body mass and the maximal running speed of an animal.
    </div>
  </div>
</div>

        </div>
      
        <div class="relative w-100  mb4 bg-white">
          <div class="relative w-100 mb4 bg-white nested-copy-line-height">
  <div class="bg-white mb3 pa4 gray overflow-hidden">
    <span class="f6 db">Posts</span>
    <h1 class="f3 near-black">
      <a href="/posts/classical_ml/linear_regression/" class="link black dim">
        Linear Regression - Explained
      </a>
    </h1>
    <div class="nested-links f5 lh-copy nested-copy-line-height">
      Introduction Linear Regression is a type of Supervised Machine Learning Algorithm, where a linear relationship between the input feature(s) and the target value is assumed. Linear Regression is a specific type of regression model, where the mapping learned by the model describes a linear function. As in all regression tasks, the target variable is continuous. In a linear regression, the linear relationship between one (Simple Linear Regression) or more (Multiple Linear Regression) independent variable and one dependent variable is modeled.
    </div>
  </div>
</div>

        </div>
      
        <div class="relative w-100  mb4 bg-white">
          <div class="relative w-100 mb4 bg-white nested-copy-line-height">
  <div class="bg-white mb3 pa4 gray overflow-hidden">
    <span class="f6 db">Posts</span>
    <h1 class="f3 near-black">
      <a href="/posts/deep_learning/intro_dl/" class="link black dim">
        Introduction to Deep Learning
      </a>
    </h1>
    <div class="nested-links f5 lh-copy nested-copy-line-height">
      In this article we will learn what Deep Learning is and understand the difference to AI and Machine Learning. Often these three terms are used interchangeable. They are however not the same. The following diagram illustrates how they are related.
Relation of Artificial Intelligence, Machine Learning and Deep Learning.
Artificial Intelligence. There are different definitions of Artificial Intelligence, but in general, they involve computers performing tasks that are usually associated with humans or other intelligent living systems.
    </div>
  </div>
</div>

        </div>
      
        <div class="relative w-100  mb4 bg-white">
          <div class="relative w-100 mb4 bg-white nested-copy-line-height">
  <div class="bg-white mb3 pa4 gray overflow-hidden">
    <span class="f6 db">Posts</span>
    <h1 class="f3 near-black">
      <a href="/posts/ml_concepts/supervised_unsupervised/" class="link black dim">
        Supervised versus Unsupervised Learning - Explained
      </a>
    </h1>
    <div class="nested-links f5 lh-copy nested-copy-line-height">
      Machine Learning In classical programming, the programmer defines specific rules which the program follows and these rules lead to an output. In contrast, Machine Learning uses data to find the rules that describe the relationship between input and output. This process of finding the rules is called &rsquo;learning&rsquo;. Supervised and Unsupervised Learning are two different types of Machine Learning. Let&rsquo;s discover what each means.
Fig. 1: Supervised and Unsupervised Learning are different types of Machine Learning.
    </div>
  </div>
</div>

        </div>
      
        <div class="relative w-100  mb4 bg-white">
          <div class="relative w-100 mb4 bg-white nested-copy-line-height">
  <div class="bg-white mb3 pa4 gray overflow-hidden">
    <span class="f6 db">Posts</span>
    <h1 class="f3 near-black">
      <a href="/posts/ml_concepts/classification_metrics/" class="link black dim">
        Metrics for Classification Problems
      </a>
    </h1>
    <div class="nested-links f5 lh-copy nested-copy-line-height">
      Classification Problems Supervised Machine Learning projects can be divided into regression and classification problems. In regression problems, we predict a continuous variable (e.g. temperature), while in classification, we classify the data into discrete classes (e.g. classify cat and dog images). A subset of classification problems is the so-called binary classification, where only two classes are considered. An example of this is classifying e-mails as spam and no-spam or cat images versus dog images.
    </div>
  </div>
</div>

        </div>
      
        <div class="relative w-100  mb4 bg-white">
          <div class="relative w-100 mb4 bg-white nested-copy-line-height">
  <div class="bg-white mb3 pa4 gray overflow-hidden">
    <span class="f6 db">Posts</span>
    <h1 class="f3 near-black">
      <a href="/posts/ml_concepts/regression_metrics/" class="link black dim">
        Metrics for Regression Problems
      </a>
    </h1>
    <div class="nested-links f5 lh-copy nested-copy-line-height">
      Regression Problems Regression problems in Machine Learning are a type of supervised learning problem, where a continuous numerical variable is predicted, such as, for example, the age of a person or the price of a product. A special type is the Linear Regression, where a linear relationship between two (Simple Linear Regression or more (Multiple Linear Regression) is analyzed. The example plots in this article will be illustrated with a simple linear regression.
    </div>
  </div>
</div>

        </div>
      
        <div class="relative w-100  mb4 bg-white">
          <div class="relative w-100 mb4 bg-white nested-copy-line-height">
  <div class="bg-white mb3 pa4 gray overflow-hidden">
    <span class="f6 db">Posts</span>
    <h1 class="f3 near-black">
      <a href="/posts/ml_concepts/datascience_lifecycle/" class="link black dim">
        The Data Science Lifecycle
      </a>
    </h1>
    <div class="nested-links f5 lh-copy nested-copy-line-height">
      Introduction When we think about Data Science, we usually think about Machine Learning modeling. However, a Data Science project consists of many more steps. Whereas modelling might be the most fun part, it is important to know that this is only a fraction of the entire lifecycle of a Data Science project. When we plan a project and communicate how much time we need, we need to make sure that enough time is given for all the surrounding tasks.
    </div>
  </div>
</div>

        </div>
      
    </section>
  </div>

    </main>
    <footer class="bg-navy bottom-0 w-100 pa3" role="contentinfo">
  <div class="flex justify-between">
  <a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href="http://localhost:1313/" >
    &copy; 
  </a>
    <div>
<div class="ananke-socials">
  
    
    <a href="https://twitter.com/datamapu" target="_blank" rel="noopener" class="twitter ananke-social-link link-transition stackoverflow link dib z-999 pt3 pt0-l mr1" title="Twitter link" aria-label="follow on Twitter——Opens in a new window">
      
        <span class="icon"><svg style="enable-background:new 0 0 67 67;" version="1.1" viewBox="0 0 67 67"  xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M37.167,22.283c-2.619,0.953-4.274,3.411-4.086,6.101  l0.063,1.038l-1.048-0.127c-3.813-0.487-7.145-2.139-9.974-4.915l-1.383-1.377l-0.356,1.017c-0.754,2.267-0.272,4.661,1.299,6.271  c0.838,0.89,0.649,1.017-0.796,0.487c-0.503-0.169-0.943-0.296-0.985-0.233c-0.146,0.149,0.356,2.076,0.754,2.839  c0.545,1.06,1.655,2.097,2.871,2.712l1.027,0.487l-1.215,0.021c-1.173,0-1.215,0.021-1.089,0.467  c0.419,1.377,2.074,2.839,3.918,3.475l1.299,0.444l-1.131,0.678c-1.676,0.976-3.646,1.526-5.616,1.568  C19.775,43.256,19,43.341,19,43.405c0,0.211,2.557,1.397,4.044,1.864c4.463,1.377,9.765,0.783,13.746-1.568  c2.829-1.673,5.657-5,6.978-8.221c0.713-1.716,1.425-4.851,1.425-6.354c0-0.975,0.063-1.102,1.236-2.267  c0.692-0.678,1.341-1.419,1.467-1.631c0.21-0.403,0.188-0.403-0.88-0.043c-1.781,0.636-2.033,0.551-1.152-0.402  c0.649-0.678,1.425-1.907,1.425-2.267c0-0.063-0.314,0.042-0.671,0.233c-0.377,0.212-1.215,0.53-1.844,0.72l-1.131,0.361l-1.027-0.7  c-0.566-0.381-1.361-0.805-1.781-0.932C39.766,21.902,38.131,21.944,37.167,22.283z M33,64C16.432,64,3,50.569,3,34S16.432,4,33,4  s30,13.431,30,30S49.568,64,33,64z" style="fill-rule:evenodd;clip-rule:evenodd;"/></svg>
</span>
      
<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000"  xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;"/>
</svg>
</span></a>
  
    
    <a href="https://www.linkedin.com/in/datamapu-ml-91a2622a3/" target="_blank" rel="noopener" class="linkedin ananke-social-link link-transition stackoverflow link dib z-999 pt3 pt0-l mr1" title="LinkedIn link" aria-label="follow on LinkedIn——Opens in a new window">
      
        <span class="icon"><svg style="enable-background:new 0 0 65 65;" version="1.1" viewBox="0 0 65 65"  xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
  <path d="M50.837,48.137V36.425c0-6.275-3.35-9.195-7.816-9.195  c-3.604,0-5.219,1.983-6.119,3.374V27.71h-6.79c0.09,1.917,0,20.427,0,20.427h6.79V36.729c0-0.609,0.044-1.219,0.224-1.655  c0.49-1.22,1.607-2.483,3.482-2.483c2.458,0,3.44,1.873,3.44,4.618v10.929H50.837z M22.959,24.922c2.367,0,3.842-1.57,3.842-3.531  c-0.044-2.003-1.475-3.528-3.797-3.528s-3.841,1.524-3.841,3.528c0,1.961,1.474,3.531,3.753,3.531H22.959z M34,64  C17.432,64,4,50.568,4,34C4,17.431,17.432,4,34,4s30,13.431,30,30C64,50.568,50.568,64,34,64z M26.354,48.137V27.71h-6.789v20.427  H26.354z" style="fill-rule:evenodd;clip-rule:evenodd;"/>
</svg>
</span>
      
<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000"  xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;"/>
</svg>
</span></a>
  
</div>
</div>
  </div>
</footer>

  </body>
</html>
